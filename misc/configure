module load python cuda; source $pyshtenv; cd pysht/c/

nvcc  -o assocLeg.so -shared -Xcompiler -fPIC assocLeg.cu
nvcc  -o pysht/c/pointing.so -shared -Xcompiler -fPIC pysht/c/pointing.cpp pysht/c/pointing.cu

srun python3 -m notebook --port=1234 --ip=$hostname

# bind the c code to python
cmake -S . -B build
cmake --build build

to install SHTns on the rusty cluster, make sure you the following to variables, otherwise SHTns will 'install' but not have updated GPU routines (not sure why)
export CUDA_PATH=/mnt/sw/nix/store/zi2wc26znf75csf5hhz77p0d2bbz53ih-cuda-11.8.0
export LD_LIBRARY_PATH=/mnt/sw/nix/store/zi2wc26znf75csf5hhz77p0d2bbz53ih-cuda-11.8.0/lib64


to run profiling:
    add decorator @profile to the function
    run kernprof -l -v script.py
    to run the script with the profiler
    python -m cProfile -o output.pstats script.py
    to visualize the output
    snakeviz output.pstats
    or
    pyprof2calltree -i output.pstats -k
    

To profile:
 1. `kernprof -l gclm2lenmap_GPU.py'`
 2. `python3 -m line_profiler -rmt "gclm2lenmap_GPU.py.lprof"


## Rusty @ Simons

```
salloc -p gpu --gpus=1 -C v100 -c 1
ssh sbelkner@<workergpuX>
remember workerid!
module load python gcc cuda
./start_jupyter (don't miss half the token..)
connect via VS Code kernel
```

## profile

to profile your code with python,

To profile this:
 1. `kernprof -l gclm2lenmap_GPU.py'`
 2. `python3 -m line_profiler -rmt "gclm2lenmap_GPU.py.lprof"`


## Ygdrassil
Quickhelp to activate GPU on jupyter notebook in VS code


Activate conda environment, and load modules before starting kernel,

```
conda activate shtgpu
source load_modules
```

Allocate GPU,
```
salloc --gpus 1 --partition=shared-gpu --time=320:00
```

Run script for starting server,

```
./start_jupyter.sh
```

In VS Code, choose exsiting server with URL.
Finally, in notebook, choose shtgpu kernel.


To install shtns, activate gpu node, load compatible modules (CUDAcore needs gcc <=10, i.e: module load GCC/9.3.0)

There appears to be two shtgpu conda environs. One is on login node, the other is on gpu node. Install stuff into the gpu node version, as only there shtns and cufinufft installations succeed.